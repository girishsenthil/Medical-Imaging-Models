{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3DResidualUNetwithAttention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPv+4PTl0zI+infn+JHORbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girishsenthil/Medical-Imaging-Models/blob/main/3DResidualUNetwithAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MxdQubCzrxOv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Blocks for Model"
      ],
      "metadata": {
        "id": "LkwhPkv-sMQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    'kernel_size': (3, 3, 3),\n",
        "    'padding': 'same',\n",
        "    'kernel_initializer': 'he_normal'\n",
        "}"
      ],
      "metadata": {
        "id": "SD_MPZ67sheG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = lambda x, filters, strides: layers.Conv3D(filters= filters, strides = strides, **kwargs)(x)\n",
        "tran = lambda x, filters, strides: layers.Conv3DTranspose(filters = filters, strides = strides, **kwargs)(x)"
      ],
      "metadata": {
        "id": "BvnXfaTLsKGG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm = lambda x: layers.BatchNormalization()(x)\n",
        "\n",
        "relu = lambda x: layers.ReLU()(x)\n",
        "sigmoid = lambda x: layers.Activation('sigmoid')(x)"
      ],
      "metadata": {
        "id": "TW52zfs0xU00"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = lambda filters, x: relu(norm(conv(x, filters, strides = 1)))\n",
        "conv2 = lambda filters, x: relu(norm(conv(x, filters, strides = (2, 2, 2))))\n",
        "tran2 = lambda filters, x: relu(norm(conv(x, filters, strides = (2, 2, 2))))"
      ],
      "metadata": {
        "id": "O2_niGiNtGLJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv1_block = lambda filters, x: conv1(filters, conv1(filters, x))"
      ],
      "metadata": {
        "id": "l4gDcbT2tTq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(filters, x):\n",
        "  '''\n",
        "  Residual Block combines normal two layer convolution with the original \n",
        "     layer projected to form a skip connection\n",
        "     \n",
        "     params: filters (desired filter size of next layer)\n",
        "             x       (previous layer to form skip connection with)\n",
        "  '''\n",
        "\n",
        "  l1 = conv1_block(filters, x)\n",
        "\n",
        "  #projecting x to same filter size as l1\n",
        "\n",
        "  residual = norm(layers.Conv3D(filters = filters,\n",
        "                                kernel_size = (1, 1, 1),\n",
        "                                padding = 'same')(x))\n",
        "  final_layer = relu(residual + l1)\n",
        "\n",
        "  return final_layer\n"
      ],
      "metadata": {
        "id": "q4tWTmMetYCx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gating_signal(x, out_size):\n",
        "  '''\n",
        "  Gating signal for implementation in Attention Module\n",
        "     \n",
        "     params: x         (layer that is used as gate before attention)\n",
        "             out_size  (filter size to project layer x to for implementation in\n",
        "                        attention module)\n",
        "  '''\n",
        "\n",
        "  res = relu(norm(layers.Conv3D(filters = out_size,\n",
        "                                kernel_size = (1, 1, 1),\n",
        "                                strides = (1, 1, 1),\n",
        "                                padding = 'same')(x)))\n",
        "  return res"
      ],
      "metadata": {
        "id": "6s8Ad0-hussE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_block(x, g):\n",
        "  '''Attention Module from Oktay Paper, adapted from DigitalSreeni Youtube Channel'''\n",
        "\n",
        "  x_shape, g_shape = K.int_shape(x), K.int_shape(g)\n",
        "\n",
        "  #Reduce feature map size of x\n",
        "\n",
        "  theta_x = layers.Conv3D(filters = x_shape[-1],\n",
        "                          kernel_size = (1, 1, 1),\n",
        "                          strides = (2, 2, 2),\n",
        "                          padding = 'same')(x)\n",
        "\n",
        "  theta_x_shape = K.int_shape(theta_x)\n",
        "\n",
        "  #Project gate to be same filter size as x\n",
        "\n",
        "  phi_g = layers.Conv3D(filters = x_shape[-1],\n",
        "                        kernel_size = (1, 1, 1),\n",
        "                        strides = (1, 1, 1),\n",
        "                        padding = 'same')(g)\n",
        "  \n",
        "  phi_g_shape = K.int_shape(phi_g)\n",
        "\n",
        "  strides = tuple(map(lambda i, j: i//j, x_shape[1:-1], phi_g_shape[1:-1]))\n",
        "\n",
        "  tran_g = layers.Conv3DTranspose(filters = x_shape[-1],\n",
        "                                  kernel_size = (3, 3, 3),\n",
        "                                  strides = strides,\n",
        "                                  padding = 'same')(phi_g)\n",
        "\n",
        "  xg = relu(phi_g + theta_x)\n",
        "\n",
        "  psi = sigmoid(layers.Conv3D(filters = 1,\n",
        "                              kernel_size = (1, 1, 1),\n",
        "                              strides = (1, 1, 1),\n",
        "                              padding = 'same')(xg))\n",
        "  \n",
        "  psi_shape = K.int_shape(psi)\n",
        "\n",
        "  size = tuple(map(lambda i, j: i//j, x_shape[1:-1], psi_shape[1:-1]))\n",
        "\n",
        "  upsampled_psi = layers.UpSampling3D(size = size)(psi)\n",
        "\n",
        "  res = norm(layers.Conv3D(filters = x_shape[-1],\n",
        "                           kernel_size = (1, 1, 1),\n",
        "                           strides = (1, 1, 1),\n",
        "                           padding = 'same')(layers.multiply([upsampled_psi, x])))\n",
        "  \n",
        "  return res"
      ],
      "metadata": {
        "id": "rXlf2I1Qvpdo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResAttentionUnet(input_shape, input_dtype, filters, logit_filters):\n",
        "\n",
        "  '''\n",
        "  UNet with Residual Blocks and Attention Module\n",
        "\n",
        "    inputs : input_shape    (shape of 3D data input this model will be trained on)\n",
        "             input_dtype    (dtype of input)\n",
        "             filters        (desired intial depth of filters. Deepest layer will have \n",
        "                            filters*16 feature maps)\n",
        "             logit_filters  (desired final layer filters, typically amount of classes\n",
        "                             in segmentation task)\n",
        "    return ; Model Backbone \n",
        "  '''\n",
        "\n",
        "  x = Input(shape = input_shape, dtype = input_dtype)\n",
        "\n",
        "\n",
        "\n",
        "  l1 = residual_block(filters, x)\n",
        "  l2 = conv1_block(filters, conv2(filters, l1))\n",
        "\n",
        "  l3 = residual_block(filters*2, l2)\n",
        "  l4 = conv1_block(filters*2, conv2(filters*2, l3))\n",
        "\n",
        "  l5 = residual_block(filters*4, l4)\n",
        "  l6 = conv1_block(filters*4, conv2(filters*4, l5))\n",
        "\n",
        "  l7 = residual_block(filters*8, l6)\n",
        "  l8 = conv1_block(filters*8, conv2(filters*8, l7))\n",
        "\n",
        "  l9 = conv1_block(filters*16, residual_block(filters*16, l8))\n",
        "\n",
        "  g1 = gating_signal(l9, filters*8)\n",
        "  a1 = attention_block(l7, g1)\n",
        "\n",
        "  l10 = tran2(filters*8, l9)\n",
        "  l11 = conv1_block(filters*8, l10 + a1)\n",
        "  l12 = residual_block(filters*8, l11)\n",
        "\n",
        "  g2 = gating_signal(l7, filters*4)\n",
        "  a2 = attention_block(l5, g2)\n",
        "\n",
        "  l13 = tran2(filters*4, l12)\n",
        "  l14 = conv1_block(filters*4, l13 + a2)\n",
        "  l15 = residual_block(filters*4, l14)\n",
        "\n",
        "  g3 = gating_signal(l5, filters*2)\n",
        "  a3 = attention_block(l3, g3)\n",
        "\n",
        "  l16 = tran2(filters*2, l15)\n",
        "  l17 = conv1_block(filters*2, l16 + a3)\n",
        "  l18 = residual_block(filters*2, l17)\n",
        "\n",
        "  g4 = gating_signal(l3, filters)\n",
        "  a4 = attention_block(l1, g4)\n",
        "\n",
        "  l19 = tran2(filters, l18)\n",
        "  l20 = conv1_block(filters, l19 + a4)\n",
        "  l21 = residual_block(filters, l20)\n",
        "\n",
        "  outputs = layers.Conv3D(filters = 2, **kwargs)(l21)\n",
        "\n",
        "  backbone = Model(inputs = x, outputs = outputs)\n",
        "\n",
        "  return backbone"
      ],
      "metadata": {
        "id": "oItm7Yc_yOVb"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}