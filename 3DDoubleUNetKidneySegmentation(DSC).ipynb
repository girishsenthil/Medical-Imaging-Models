{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3DDoubleUNetKidneySegmentation(DSC).ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMfCn5i6aGMXN+tAu2UPHRT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girishsenthil/Medical-Imaging-Models/blob/main/3DDoubleUNetKidneySegmentation(DSC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQa7uVNIAgG6",
        "outputId": "0700d97e-c194-4b9d-ae4e-fab7a44dba94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jarvis-md\n",
            "  Downloading jarvis_md-0.0.1a17-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Collecting pyyaml>=5.2\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->jarvis-md) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->jarvis-md) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2022.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a17 pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "% pip install jarvis-md"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
        "from jarvis.train import datasets"
      ],
      "metadata": {
        "id": "ZyXx6iRlAoG_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.download(name='ct/kits')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoW5NTdLA7JT",
        "outputId": "5abec210-4229-4d2d-807c-1dc3c1a3ff2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-07-18 15:56:50 ] [====================] 100.000% : Extracting archive (0000818 / 0000818) "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': '/data/raw/ct_kits', 'data': '/data/raw/ct_kits'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing residual, inception, and squeeze&excite models"
      ],
      "metadata": {
        "id": "S5M6XSB5IZWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual(a, b):\n",
        "\n",
        "  a_shape, b_shape = a.shape.as_list(), b.shape.as_list()\n",
        "\n",
        "  if a_shape != b_shape:\n",
        "\n",
        "    filters = a_shape[-1]\n",
        "    i, j = b_shape[2] / a_shape[2], b_shape[3] / a_shape [3]\n",
        "\n",
        "    strides = (1, int(i), int(j))\n",
        "\n",
        "    kernel_size = 1 if strides == (1, 1, 1) else (1, 3, 3)\n",
        "\n",
        "    b = layers.Conv3D(filters = filters, kernel_size = kernel_size,\n",
        "                      strides = strides, padding = 'same')(b)\n",
        "    return a + b\n",
        "\n",
        "def inception(a, filters):\n",
        "\n",
        "  # --- Define lambda functions\n",
        "  conv = lambda x, filters,kernel_size : layers.Conv3D(\n",
        "      filters=filters, \n",
        "      kernel_size=kernel_size, \n",
        "      padding='same')(x)\n",
        "\n",
        "  norm = lambda x : layers.BatchNormalization()(x)\n",
        "  relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "  # --- Define 1x1, 3x3, 5x5 convs and 3x3 pools\n",
        "  conv1 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 1, 1))))\n",
        "  conv3 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 3, 3))))\n",
        "  conv5 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=(1, 5, 5))))\n",
        "  mpool = lambda x : layers.MaxPool3D(pool_size=(1, 3, 3), strides=1, padding='same')(x)\n",
        "  \n",
        "  filters_sub = int(filters/4)\n",
        "\n",
        "  p1 = conv1(filters_sub, a)\n",
        "  p2 = conv3(filters_sub, conv1(filters, a))\n",
        "  p3 = conv5(filters_sub, conv1(filters, a))\n",
        "  p4 = conv1(filters_sub, mpool(a))\n",
        "\n",
        "  return layers.Concatenate()([p1, p2, p3, p4])\n",
        "\n",
        "def se(a, r=16):\n",
        "\n",
        "  sqz = layers.AveragePooling3D((1, a.shape[2], a.shape[3]))(a)\n",
        "  cha = int(a.shape[-1]/r)\n",
        "  exc = layers.Conv3D(filters = cha, kernel_size = 1, activation = 'relu')(sqz)\n",
        "  sca = layers.Conv3D(filters = a.shape[-1], kernel_size = 1, activation = 'sigmoid')(exc)\n",
        "\n",
        "  return a * sca"
      ],
      "metadata": {
        "id": "VKRvS6BIBlZL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_dsc(y_true, y_pred, c=1):\n",
        "    \"\"\"\n",
        "    Method to calculate the Dice score coefficient for given class\n",
        "    \n",
        "    :params\n",
        "    \n",
        "      y_true : ground-truth label\n",
        "      y_pred : predicted logits scores\n",
        "           c : class to calculate DSC on\n",
        "    \n",
        "    \"\"\"    \n",
        "    true = y_true[..., 0] == c\n",
        "    pred = tf.math.argmax(y_pred, axis=-1) == c \n",
        "\n",
        "    A = tf.math.count_nonzero(true & pred) * 2\n",
        "    B = tf.math.count_nonzero(true) + tf.math.count_nonzero(pred)\n",
        "    \n",
        "    return tf.math.divide_no_nan(\n",
        "        tf.cast(A, tf.float32), \n",
        "        tf.cast(B, tf.float32))"
      ],
      "metadata": {
        "id": "E4oFH-sSByLV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = {'batch': {'size': 2}}\n",
        "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='3d-bin', configs=configs, custom_layers=True)"
      ],
      "metadata": {
        "id": "qDhHkYB2B2Pt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    'kernel_size': (3, 3, 3),\n",
        "    'padding': 'same',\n",
        "    'kernel_initializer': 'he_normal'}\n",
        "\n",
        "# --- Define Building Block Lambda\n",
        "conv = lambda x, filters, strides: layers.Conv3D(filters = filters, strides = strides,\n",
        "                                                 **kwargs)(x)\n",
        "tran = lambda x, filters, strides: layers.Conv3DTranspose(filters = filters, strides = strides,\n",
        "                                                          **kwargs)(x)\n",
        "norm = lambda x: layers.BatchNormalization()(x)\n",
        "relu = lambda x: layers.ReLU()(x)\n",
        "\n",
        "conv1 = lambda filters, x: relu(norm(conv(x, filters, strides = 1)))\n",
        "conv2 = lambda filters, x: relu(norm(conv(x, filters, strides = (2, 2, 2))))\n",
        "tran2 = lambda filters, x: relu(norm(tran(x, filters, strides = (2, 2, 2))))\n",
        "\n",
        "concat = lambda a, b: layers.Concatenate()([a, b])"
      ],
      "metadata": {
        "id": "wRIDOHAOB8st"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Input(shape=(96, 96, 96, 1), dtype='float32')"
      ],
      "metadata": {
        "id": "DVir17TQB_v0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon learning about U-net, I wondered why this encoder-decoder model would not work better by just doubling the architecture and adding more skip connections in. However, as I have read more about different types of models I have come to the understanding that despite have a large amount of trainable parameters, they will not necessarily train well, or they will not yield significantly higher performance metrics for the trade-off of being extremely computationally intensive. \n",
        "\n",
        "Overall, I believe that smaller models with more effective mechanisms will out-perform this model"
      ],
      "metadata": {
        "id": "v-og6OqgF7CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Contract 1\n",
        "\n",
        "l1 = conv1(8, x)\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, se(conv2(32, l2)))\n",
        "l4 = conv1(48, se(conv2(48, l3)))\n",
        "l5 = conv1(64, se(conv2(64, l4)))\n",
        "l6 = conv1(80, se(conv2(80, l5)))\n",
        "\n",
        "#Expand 1\n",
        "\n",
        "l7 = tran2(64, l6)\n",
        "l8 = tran2(48, conv1(64, l7 + l5))\n",
        "l9 = tran2(32, conv1(48, l8 + l4))\n",
        "l10 = tran2(16, conv1(32, l9 + l3))\n",
        "l11 = tran2(8, conv1(16, l10 + l2))\n",
        "\n",
        "#Contract 1\n",
        "\n",
        "l12 = conv1(16, conv2(16, l11))\n",
        "l13 = conv1(32, conv2(32, l12 + l10))\n",
        "l14 = conv1(48, conv2(48, l13 + l9))\n",
        "l15 = conv1(64, conv2(64, l14 + l8))\n",
        "l16 = conv1(80, conv2(80, l15 + l7))\n",
        "\n",
        "#Expand 1\n",
        "\n",
        "l17 = tran2(64, conv1(80, l16 + l6))\n",
        "l18 = tran2(48, conv1(64, l17 + l15))\n",
        "l19 = tran2(32, conv1(48, l18 + l14))\n",
        "l20 = tran2(16, conv1(32, l19 + l13))\n",
        "l21 = tran2(8, conv1(16, l20 + l12))"
      ],
      "metadata": {
        "id": "IlHbFCiJCBsT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = layers.Conv3D(filters = 2, **kwargs)"
      ],
      "metadata": {
        "id": "CUHpJntPEH-G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = {\n",
        "    'c0': layers.Conv3D(filters=2, **kwargs)(l21),\n",
        "    'c1': layers.Conv3D(filters=2, **kwargs)(l20),\n",
        "}"
      ],
      "metadata": {
        "id": "oNwfm-TIENFb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "XGJWRhqvEdOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = Model(inputs = x, outputs = logits)"
      ],
      "metadata": {
        "id": "p_ZkLOKiEbMF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    'dat': Input(shape=(96, 96, 96, 1), name='dat'),\n",
        "    'lbl': Input(shape=(96, 96, 96, 1), name='lbl')}"
      ],
      "metadata": {
        "id": "GAY51NrFEgJ1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = backbone(inputs['dat'])"
      ],
      "metadata": {
        "id": "G40cb233EhAQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Loss Parameters, Using SCE Loss to calculate pixel loss"
      ],
      "metadata": {
        "id": "cKFkmdFMFziM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = {}\n",
        "true = inputs['lbl']\n",
        "\n",
        "for c in sorted(logits.keys()):\n",
        "  if c != 'c0':\n",
        "    true = layers.MaxPooling3D(pool_size = (2, 2, 2))(true)\n",
        "    \n",
        "  loss[c] = losses.SparseCategoricalCrossentropy(from_logits = True, name = 'sce-' + c)(\n",
        "      y_true = true,\n",
        "      y_pred = logits[c])"
      ],
      "metadata": {
        "id": "yCN5d72eEiem"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dsc = calculate_dsc(y_true = inputs['lbl'], y_pred = logits['c0'])"
      ],
      "metadata": {
        "id": "xkwo_3vlEkDX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = Model(inputs = inputs, outputs = {**logits, **loss, **{'dsc': dsc}})"
      ],
      "metadata": {
        "id": "YciLQ1CpEs0l"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for loss in loss.values():\n",
        "  training.add_loss(loss)"
      ],
      "metadata": {
        "id": "4T_2Eyt8Euoi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.add_metric(dsc, name = 'dsc')"
      ],
      "metadata": {
        "id": "qhd6EGD1Ev27"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop loss with momentum works very well with deep learning models with large amounts of parameters"
      ],
      "metadata": {
        "id": "IOiw2GwTFV9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.RMSprop(learning_rate = 3e-4)"
      ],
      "metadata": {
        "id": "zn_H3bepEw92"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.load_data_in_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64uZDcycEx8-",
        "outputId": "8bccab83-d026-4990-e80d-da40d97fcb9b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-07-18 16:10:35 ] [====================] 100.000% : Iterating | 000402    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.compile(optimizer = optimizer)"
      ],
      "metadata": {
        "id": "GQJoONLyE--Y"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.fit(x = gen_train,\n",
        "             steps_per_epoch = 100,\n",
        "             epochs = 20,\n",
        "             validation_data = gen_valid,\n",
        "             validation_steps = 100,\n",
        "             validation_freq = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo2-VA93Ez59",
        "outputId": "7a730797-bdcc-45cb-921f-3d8f8ec1912a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 50s 270ms/step - loss: 0.6911 - dsc: 0.1075\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.1262 - dsc: 0.6340\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0615 - dsc: 0.9245\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0493 - dsc: 0.9380\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 35s 353ms/step - loss: 0.0465 - dsc: 0.9423 - val_loss: 0.0448 - val_dsc: 0.9496\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0396 - dsc: 0.9495\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0318 - dsc: 0.9576\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0370 - dsc: 0.9533\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0278 - dsc: 0.9634\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 35s 346ms/step - loss: 0.0289 - dsc: 0.9616 - val_loss: 0.0342 - val_dsc: 0.9602\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0277 - dsc: 0.9629\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0244 - dsc: 0.9673\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0257 - dsc: 0.9658\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0240 - dsc: 0.9670\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 34s 344ms/step - loss: 0.0215 - dsc: 0.9707 - val_loss: 0.0366 - val_dsc: 0.9586\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0218 - dsc: 0.9695\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0202 - dsc: 0.9726\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0197 - dsc: 0.9726\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0178 - dsc: 0.9746\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 34s 344ms/step - loss: 0.0187 - dsc: 0.9747 - val_loss: 0.0307 - val_dsc: 0.9676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3158608b50>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "7u08ODhFE7pc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(backbone)"
      ],
      "metadata": {
        "id": "oFKI8TqBHbzG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}